<!doctype html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Research | ICAROS</title><link rel="canonical" href="https://icaros.usc.edu/research/"><link rel="alternate" type="application/atom+xml" title="ICAROS Lab Blog" href="/feed.xml"><meta name="description" content="An overview of our research areas and contributions."><meta property="og:title" content="Research"><meta property="og:type" content="website"><meta property="og:url" content="https://icaros.usc.edu/research/"><meta property="og:image" content="https://icaros.usc.edu/imgs/open-graph-preview.png"><meta property="og:description" content="An overview of our research areas and contributions."><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Research"><meta name="twitter:description" content="An overview of our research areas and contributions."><meta name="twitter:image" content="https://icaros.usc.edu/imgs/twitter-preview.png"><link rel="stylesheet" href="/assets/main.css?f39a8985f5af1fc208c5f5625bb2221e"><link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.1/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"><link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png"><link rel="manifest" href="/favicon/site.webmanifest"><link rel="mask-icon" href="/favicon/safari-pinned-tab.svg" color="#000000"><link rel="shortcut icon" href="/favicon/favicon.ico"><meta name="msapplication-TileColor" content="#000000"><meta name="msapplication-config" content="/favicon/browserconfig.xml"><meta name="theme-color" content="#ffffff"></head><body class="flex flex-col min-h-screen"><div style="min-height:80vh"><header><nav class="w-full relative bg-white z-40" style="box-shadow:0 2px 4px rgba(0,0,0,.2)"><div class="mx-auto flex flex-wrap items-center justify-between max-w-screen-2xl md:px-4 p-0"><div class="w-full md:w-auto flex flex-wrap items-center justify-between md:justify-start"><div class="border-b-4 border-black pb-0.5 transition border-opacity-0 hover:border-opacity-100 z-50 md:ml-1 md:my-0 ml-5 mr-2 my-4" style="padding-top:4px"><a href="/"><img src="/imgs/logo/black.svg" class="h-10 inline-block" alt="ICAROS" loading="lazy"></a></div><input class="absolute top-0 cursor-pointer md:hidden mr-5 mt-5 nav-checkbox opacity-0 right-0 z-50" style="width:32px;height:28px" type="checkbox"><div class="md:hidden mr-4 my-4 nav-hamburger"><div id="hamburger" class="duration-300 ease transition-all cursor-pointer mx-2 relative" style="width:26px;height:22px"><div class="absolute bg-black duration-300 ease hamburger-bar transition-all bar1" style="top:0;width:26px;height:2px"></div><div class="absolute bg-black duration-300 ease hamburger-bar transition-all bar2" style="top:10px;width:26px;height:2px"></div><div class="absolute bg-black duration-300 ease hamburger-bar transition-all bar3" style="top:20px;width:26px;height:2px"></div></div></div><style>.nav-checkbox:checked~.nav-hamburger .bar1{transform:translateY(10px) rotate(45deg);transition:all .2s ease}.nav-checkbox:checked~.nav-hamburger .bar2{opacity:0;transition:all .2s ease}.nav-checkbox:checked~.nav-hamburger .bar3{transform:translateY(-10px) rotate(-45deg);transition:all .2s ease}</style><div class="w-full md:w-auto hidden md:flex md:py-0 md:text-left nav-menu pb-3 text-center"><div class="mb-1 block md:inline-block md:my-6 mt-3 mx-3"><a href="/research/" class="hover:no-underline border-b-4 border-black pb-0.5 pt-1 text-black transition hover:border-gray-400 hover:text-gray-400">Research</a></div><div class="mb-1 block md:inline-block md:my-6 mt-3 mx-3"><a href="/people/" class="hover:no-underline border-b-4 border-black pb-0.5 pt-1 text-black transition border-opacity-0 hover:border-opacity-100 hover:text-black">People</a></div><div class="mb-1 block md:inline-block md:my-6 mt-3 mx-3"><a href="/publications/" class="hover:no-underline border-b-4 border-black pb-0.5 pt-1 text-black transition border-opacity-0 hover:border-opacity-100 hover:text-black">Publications</a></div><div class="mb-1 block md:inline-block md:my-6 mt-3 mx-3"><a href="/press/" class="hover:no-underline border-b-4 border-black pb-0.5 pt-1 text-black transition border-opacity-0 hover:border-opacity-100 hover:text-black">Press</a></div><div class="mb-1 block md:inline-block md:my-6 mt-3 mx-3"><a href="/videos/" class="hover:no-underline border-b-4 border-black pb-0.5 pt-1 text-black transition border-opacity-0 hover:border-opacity-100 hover:text-black">Videos</a></div></div><style>.nav-checkbox:checked~.nav-hamburger~.nav-menu{display:block}.group-checkbox:checked~.group-menu{display:block}</style></div><div class="border-b-4 border-black pb-0.5 transition border-opacity-0 hover:border-opacity-100 z-50 hidden lg:mr-5 md:block my-0" style="padding-top:4px"><a href="https://usc.edu"><img src="/imgs/usc.png" class="h-10 inline-block" alt="USC" loading="lazy"></a></div></div></nav></header><main class="flex-grow"><div class="mx-auto __research__ max-w-screen-lg prose px-4 py-8"><h2 id="research-overview">Research Overview <a class="permalink" href="#research-overview">¶</a></h2><p>Our lab focuses on enabling robots to assist human teammates in real-world manipulation tasks. We develop frameworks for robot learning in three levels of abstraction:</p><ol><li><strong>Low-level motor skills:</strong> The robot learns, executes and refines motor skills that use tools to perform physical tasks.</li><li><strong>High-level task actions:</strong> The robot learns which action to perform and which objects to manipulate, given the current world state and internal and physical state of the user.</li><li><strong>Whom to assist:</strong> The robot learns which user to assist in order to optimize performance, while accounting for human trust in the robot.</li></ol><h2 id="research-contribution-%231%3A-low-level-motor-skills">Research Contribution #1: Low-level motor skills <a class="permalink" href="#research-contribution-%231%3A-low-level-motor-skills">¶</a></h2><p><em>The robot learns, executes, and refines motor skills that use tools to perform physical tasks.</em></p><p>Much work in robotics has focused on “human-in-the-loop” learning techniques that improve the efficiency of the learning process. However, these algorithms have made the strong assumption of a cooperating human supervisor that assists the robot. In reality, human observers tend to also act in an adversarial manner towards deployed robotic systems. We show that this can in fact improve the robustness of the learned models by proposing a physical framework that leverages perturbations applied by a human adversary, guiding the robot towards more robust models. In a manipulation task, we show that grasping success improves significantly when the robot trains with a human adversary as compared to training in a self-supervised manner.</p><div class="w-full md:w-2/3 mx-auto"><div class="w-full relative h-0" style="padding-bottom:56.25%"><iframe title="Showing Robots 'Tough Love' Makes Them Stronger" class="w-full absolute h-full left-0 top-0" src="https://www.youtube.com/embed/TixzSbunn5A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div><h2 id="research-contribution-%232%3A-high-level-task-actions">Research Contribution #2: High-level task actions <a class="permalink" href="#research-contribution-%232%3A-high-level-task-actions">¶</a></h2><p><em>The robot learns which action to perform and which objects to manipulate, given the current world state and internal and physical state of the user.</em></p><p>People often watch videos on the web to learn how to cook new recipes, assemble furniture or repair a computer. We wish to enable robots with the very same capability. This is challenging; there is a large variation in manipulation actions and some videos even involve multiple persons, who collaborate by sharing and exchanging objects and tools. Furthermore, the learned representations need to be general enough to be transferable to robotic systems. Previous systems have enabled generation of semantic and human-interpretable robot commands in the form of visual sentences. However, they require manual selection of short action clips, which are then individually processed. We propose a framework for executing demonstrated action sequences from full-length, unconstrained videos on the web. The framework takes as input a video annotated with object labels and bounding boxes, and outputs a collaborative manipulation action plan for one or more robotic arms. We demonstrate the performance of the system in three full-length collaborative cooking videos on the web and propose an open-source platform for executing the learned plans in a simulation environment.</p><div class="w-full md:w-2/3 mx-auto"><div class="w-full relative h-0" style="padding-bottom:56.25%"><iframe title="Learning From Videos" class="w-full absolute h-full left-0 top-0" src="https://www.youtube.com/embed/iNN5q-IHiJg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div><h2 id="research-contribution-%233%3A-whom-to-assist">Research Contribution #3: Whom to assist <a class="permalink" href="#research-contribution-%233%3A-whom-to-assist">¶</a></h2><p><em>The robot learns which user to assist in order to optimize performance, while accounting for human trust in the robot.</em></p><p>Much work in robotics and operations research has focused on optimal resource distribution, where an agent dynamically decides how to sequentially distribute resources among different candidates. However, most work ignores the notion of fairness in candidate selection. In the case where a robot distributes resources to human team members, disproportionately favoring the highest performing teammate can have negative effects in team dynamics and system acceptance. We introduce a multi-armed bandit algorithm with fairness constraints, where a robot distributes resources to human teammates of different skill levels. In this problem, the robot does not know the skill level of each human teammate, but learns it by observing their performance over time. We define fairness as a constraint on the minimum rate that each human teammate is selected throughout the task. We provide theoretical guarantees on performance and perform a large-scale user study, where we adjust the level of fairness in our algorithm. Results show that fairness in resource distribution has a significant effect on users’ trust in the system.</p></div></main></div><div class="flex-grow"></div><footer><div class="w-full text-center bg-gray-100 p-6"><div class="mx-auto max-w-screen-2xl"><div class="mx-auto flex flex-wrap justify-center"><a href="https://github.com/icaros-usc/" title="GitHub (icaros-usc)" class="flex items-center bg-white h-12 hover:bg-gray-200 hover:no-underline hover:text-primary-dark justify-center mx-1 rounded-full text-2xl text-primary w-12"><i class="mx-auto fab fa-github"></i> </a><a href="https://www.youtube.com/channel/UCUuIwdCu3yXZBv-KtPS5TvQ" title="YouTube" class="flex items-center bg-white h-12 hover:bg-gray-200 hover:no-underline hover:text-primary-dark justify-center mx-1 rounded-full text-2xl text-primary w-12"><i class="mx-auto fab fa-youtube"></i> </a><a href="https://twitter.com/icaroslab" title="Twitter (@icaroslab)" class="flex items-center bg-white h-12 hover:bg-gray-200 hover:no-underline hover:text-primary-dark justify-center mx-1 rounded-full text-2xl text-primary w-12"><i class="mx-auto fab fa-twitter"></i> </a><a href="mailto:nikolaid@usc.edu" title="Email (nikolaid@usc.edu)" class="flex items-center bg-white h-12 hover:bg-gray-200 hover:no-underline hover:text-primary-dark justify-center mx-1 rounded-full text-2xl text-primary w-12"><i class="mx-auto fa-envelope fas"></i></a></div><div class="w-full flex flex-wrap justify-center md:flex-nowrap pt-3 text-black"><p class="w-full md:w-auto md:order-1 order-3">© ICAROS Lab 2021</p><p class="hidden md:inline px-1 order-2">|</p><p class="w-full md:w-auto md:order-3 order-5">In memory of <a href="https://www.linkedin.com/in/jignesh-modi-7819a8b8">Jignesh</a></p><p class="hidden md:inline px-1 order-4">|</p><p class="w-full md:w-auto mb-1 md:mb-0 md:order-5 order-1">See anything wrong? <a href="https://github.com/icaros-usc/icaros-usc.github.io/issues/new/">Raise an Issue</a></p></div></div></div></footer><script src="/assets/main.js?e49202d1526e360b0fe7399dd607d56b"></script><script src="/assets/vendor.js?40d6fac326e5360678edc8ddd7f519b8"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script><script>new ClipboardJS(".clipboard")</script></body></html>